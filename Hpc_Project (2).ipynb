{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWiMxzkmLTJf",
    "outputId": "3b355f99-412f-4555-cc18-d458ca66fbf4"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtYi6oH-MixV",
    "outputId": "d6bb6589-84a7-451b-a701-c5d580751622"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSN131ZJMnA8",
    "outputId": "bd7e3f53-19e8-45ac-e268-34e9b648d8ff"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXxqT_CKMuio"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USL7GH-a6Tbx",
    "outputId": "6288f7fa-942c-4fb8-b2e7-3e997a4fd389"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the CSV data\n",
    "csv_path = '/Brain_MRI_Dataset/mri_dataset/Brain_MRI_conditions.csv'\n",
    "csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Basic preprocessing of the CSV dataset\n",
    "# Keep 'Type', 'Description', and 'Body Part' columns for now\n",
    "csv_data = csv_data[['Type', 'Description', 'Body Part']]\n",
    "csv_data.fillna('', inplace=True)\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in csv_data.columns:\n",
    "    le = LabelEncoder()\n",
    "    csv_data[col] = le.fit_transform(csv_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Paths to the tumor and no tumor image folders\n",
    "tumor_folders = ['/Brain_MRI_Dataset/Training/glioma', '/Brain_MRI_Dataset/Training/meningioma', '/Brain_MRI_Dataset/Training/pituitary']\n",
    "no_tumor_folder = '/Brain_MRI_Dataset/Training/notumor'\n",
    "\n",
    "# Function to load and preprocess images from a folder\n",
    "def load_images_from_folder(folder, label, img_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img / 255.0  # Normalize to 0-1 range\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load tumor and no tumor images from multiple folders\n",
    "X_images = []\n",
    "y_labels = []\n",
    "\n",
    "# Load tumor images from the 3 tumor folders\n",
    "for tumor_folder in tumor_folders:\n",
    "    tumor_images, tumor_labels = load_images_from_folder(tumor_folder, label=1)  # Label 1 for tumor\n",
    "    X_images.extend(tumor_images)\n",
    "    y_labels.extend(tumor_labels)\n",
    "\n",
    "# Load no tumor images\n",
    "no_tumor_images, no_tumor_labels = load_images_from_folder(no_tumor_folder, label=0)  # Label 0 for no tumor\n",
    "X_images.extend(no_tumor_images)\n",
    "y_labels.extend(no_tumor_labels)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_images = np.array(X_images)\n",
    "y_labels = np.array(y_labels)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a CNN model for image classification\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification: cancer or no cancer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save('brain_mri_cancer_model.h5')\n",
    "\n",
    "# To make predictions\n",
    "def predict_cancer(img_path, model):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = img / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    prediction = model.predict(img)\n",
    "    if prediction > 0.5:\n",
    "        return \"Cancer\"\n",
    "    else:\n",
    "        return \"No Cancer\"\n",
    "\n",
    "# Example prediction\n",
    "new_image_path = '/Brain_MRI_Dataset/Testing/glioma/Te-glTr_0000.jpg'\n",
    "result = predict_cancer(new_image_path, model)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRqPyCVeDVsK",
    "outputId": "dc24a949-2def-47d7-a832-7e63075e278a"
   },
   "outputs": [],
   "source": [
    "new_image_path = 'Brain_MRI_Dataset/Testing/notumor/Te-noTr_0000.jpg'\n",
    "result = predict_cancer(new_image_path, model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1LXxkWgDosj",
    "outputId": "2c8a9668-f983-455d-f8d2-d940dd63609a"
   },
   "outputs": [],
   "source": [
    "new_image_path = '/Brain_MRI_Dataset/Testing/glioma/Te-gl_0294.jpg'\n",
    "result = predict_cancer(new_image_path, model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "id": "0G727z9b-oJJ",
    "outputId": "bd2b173e-6644-4ac2-b5c4-ce9de3e77850"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot accuracy and loss curves\n",
    "def plot_accuracy_loss(history):\n",
    "    # Plotting the training and validation accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Train the model and save history\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Plot the accuracy and loss curves\n",
    "plot_accuracy_loss(history)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jdcTVj01Fkiv"
   },
   "source": [
    "## **Use Parallel Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOXOyo8ZFoJa",
    "outputId": "a8cf41f7-8843-443c-cd63-5b423f5ac268"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the CSV data\n",
    "csv_path = '/Brain_MRI_Dataset/Brain_MRI_conditions.csv'\n",
    "csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Basic preprocessing of the CSV dataset\n",
    "# Keep 'Type', 'Description', and 'Body Part' columns for now\n",
    "csv_data = csv_data[['Type', 'Description', 'Body Part']]\n",
    "csv_data.fillna('', inplace=True)\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in csv_data.columns:\n",
    "    le = LabelEncoder()\n",
    "    csv_data[col] = le.fit_transform(csv_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Paths to the tumor and no tumor image folders\n",
    "tumor_folders = ['/Brain_MRI_Dataset/Training/glioma',\n",
    "                 '/Brain_MRI_Dataset/Training/meningioma',\n",
    "                 '/Brain_MRI_Dataset/Training/pituitary']\n",
    "no_tumor_folder = '/Brain_MRI_Dataset/Training/notumor'\n",
    "\n",
    "# Function to load and preprocess a single image (helper function)\n",
    "def process_single_image(file_info):\n",
    "    folder, filename, label, img_size = file_info\n",
    "    img_path = os.path.join(folder, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = img / 255.0  # Normalize to 0-1 range\n",
    "        return img, label\n",
    "    return None, None\n",
    "\n",
    "# Function to load and preprocess images from multiple folders in parallel\n",
    "def load_images_parallel(folders, labels, img_size=(128, 128)):\n",
    "    images = []\n",
    "    labels_list = []\n",
    "    all_files = []\n",
    "\n",
    "    # Prepare the list of files to process\n",
    "    for folder, label in zip(folders, labels):\n",
    "        for filename in os.listdir(folder):\n",
    "            all_files.append((folder, filename, label, img_size))\n",
    "\n",
    "    # Use ThreadPoolExecutor to load images in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(process_single_image, all_files)\n",
    "\n",
    "    # Collect valid images and labels from the results\n",
    "    for img, label in results:\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels_list.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels_list)\n",
    "\n",
    "# Load tumor and no tumor images in parallel\n",
    "tumor_folders_labels = [1] * len(tumor_folders)  # Tumor: label 1\n",
    "folders = tumor_folders + [no_tumor_folder]\n",
    "labels = tumor_folders_labels + [0]  # No tumor: label 0\n",
    "\n",
    "# Load images from tumor and no tumor folders\n",
    "X_images, y_labels = load_images_parallel(folders, labels)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a CNN model for image classification\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification: cancer or no cancer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save('brain_mri_cancer_model.h5')\n",
    "\n",
    "# To make predictions\n",
    "def predict_cancer(img_path, model):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = img / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    prediction = model.predict(img)\n",
    "    if prediction > 0.5:\n",
    "        return \"Cancer\"\n",
    "    else:\n",
    "        return \"No Cancer\"\n",
    "\n",
    "# Example prediction\n",
    "new_image_path = '/Brain_MRI_Dataset/Testing/glioma/Te-glTr_0000.jpg'\n",
    "result = predict_cancer(new_image_path, model)\n",
    "print(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ypnDym0cGCxR"
   },
   "source": [
    "1.35s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_M-Q6PhRHYgr"
   },
   "source": [
    "## **Performance Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXaT1S79HcMv",
    "outputId": "932a0c5e-c46f-4afb-a800-4fadb501d1fc"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Serial version\n",
    "def load_images_serial(folders, labels, img_size=(128, 128)):\n",
    "    images = []\n",
    "    labels_list = []\n",
    "\n",
    "    for folder, label in zip(folders, labels):\n",
    "        for filename in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, img_size)\n",
    "                img = img / 255.0  # Normalize to 0-1 range\n",
    "                images.append(img)\n",
    "                labels_list.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels_list)\n",
    "\n",
    "# Measure time for serial loading\n",
    "start_time_serial = time.time()\n",
    "X_images_serial, y_labels_serial = load_images_serial(folders, labels)\n",
    "end_time_serial = time.time()\n",
    "serial_time = end_time_serial - start_time_serial\n",
    "print(f\"Serial execution time: {serial_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "3_yOxAYnKgwv",
    "outputId": "3f14f4fd-2b48-45d0-e865-b465f1dbc047"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Load and preprocess the CSV data\n",
    "csv_path = '/content/drive/MyDrive/Project_Dataset/Brain_MRI_conditions.csv'\n",
    "csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Basic preprocessing of the CSV dataset\n",
    "csv_data = csv_data[['Type', 'Description', 'Body Part']]\n",
    "csv_data.fillna('', inplace=True)\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in csv_data.columns:\n",
    "    le = LabelEncoder()\n",
    "    csv_data[col] = le.fit_transform(csv_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Paths to the tumor and no tumor image folders\n",
    "tumor_folders = ['/Brain_MRI_Dataset/Training/glioma',\n",
    "                 '/Brain_MRI_Dataset/Training/meningioma',\n",
    "                 '/Brain_MRI_Dataset/Training/pituitary']\n",
    "no_tumor_folder = '/Brain_MRI_Dataset/Training/notumor'\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_single_image(file_info):\n",
    "    folder, filename, label, img_size = file_info\n",
    "    img_path = os.path.join(folder, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = img / 255.0  # Normalize to 0-1 range\n",
    "        return img, label\n",
    "    return None, None\n",
    "\n",
    "# Function to load images in parallel\n",
    "def load_images_parallel(folders, labels, img_size=(128, 128)):\n",
    "    images = []\n",
    "    labels_list = []\n",
    "    all_files = []\n",
    "\n",
    "    for folder, label in zip(folders, labels):\n",
    "        for filename in os.listdir(folder):\n",
    "            all_files.append((folder, filename, label, img_size))\n",
    "\n",
    "    # Use ThreadPoolExecutor to load images in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(process_single_image, all_files)\n",
    "\n",
    "    for img, label in results:\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels_list.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels_list)\n",
    "\n",
    "# Measure time for parallel loading\n",
    "folders = tumor_folders + [no_tumor_folder]\n",
    "tumor_folders_labels = [1] * len(tumor_folders)  # Tumor: label 1\n",
    "labels = tumor_folders_labels + [0]  # No tumor: label 0\n",
    "\n",
    "start_time_parallel = time.time()\n",
    "X_images_parallel, y_labels_parallel = load_images_parallel(folders, labels)\n",
    "end_time_parallel = time.time()\n",
    "parallel_time = end_time_parallel - start_time_parallel\n",
    "print(f\"Parallel execution time: {parallel_time:.2f} seconds\")\n",
    "\n",
    "# Measure time for serial loading\n",
    "def load_images_serial(folders, labels, img_size=(128, 128)):\n",
    "    images = []\n",
    "    labels_list = []\n",
    "\n",
    "    for folder, label in zip(folders, labels):\n",
    "        for filename in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, img_size)\n",
    "                img = img / 255.0  # Normalize to 0-1 range\n",
    "                images.append(img)\n",
    "                labels_list.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels_list)\n",
    "\n",
    "# Measure time for serial loading\n",
    "start_time_serial = time.time()\n",
    "X_images_serial, y_labels_serial = load_images_serial(folders, labels)\n",
    "end_time_serial = time.time()\n",
    "serial_time = end_time_serial - start_time_serial\n",
    "print(f\"Serial execution time: {serial_time:.2f} seconds\")\n",
    "\n",
    "# Plot the performance comparison\n",
    "times = [serial_time, parallel_time]\n",
    "methods = ['Serial', 'Parallel']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(methods, times, color=['blue', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Performance Comparison: Serial vs Parallel Image Loading')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hpd4UbEIL5-x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REdYEs6zL6Wc",
    "outputId": "82380fe5-3089-4e1c-fa9f-9764e3a91ae0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IeA1tl2L9D8"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfid9XY9MBmO"
   },
   "outputs": [],
   "source": [
    "# Enable mixed precision if supported\n",
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
